{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dnsDGhPMGr9I",
    "outputId": "4294b93f-f857-4664-9c2e-82947d3adc90"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "WD9G6yH8GzVu"
   },
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCVqzHiLGzXs"
   },
   "outputs": [],
   "source": [
    "# Import data \n",
    "\n",
    "def file_reader(filepath):\n",
    "    \n",
    "    image_nifti = nib.load(filepath)\n",
    "    img = image_nifti.get_data()\n",
    "  \n",
    "  \n",
    "    return img\n",
    "\n",
    "path = \"/content/drive/My Drive/MISA project/misa data\"\n",
    "\n",
    "# read data \n",
    "\n",
    "folders = [\"Training_Set\",\"Validation_Set\",\"Test_Set\"]\n",
    "\n",
    "\n",
    "train_folders = [f for f in sorted(os.listdir(os.path.join(path,folders[0])))]\n",
    "val_folders = [f for f in sorted(os.listdir(os.path.join(path,folders[1])))]\n",
    "test_folders = [f for f in sorted(os.listdir(os.path.join(path,folders[2])))]\n",
    "\n",
    "train_data = []\n",
    "train_labels = []\n",
    "\n",
    "print(\"Train \")\n",
    "\n",
    "for i,name in enumerate(train_folders):\n",
    "  train_data.append(file_reader(os.path.join(path,folders[0],name, name+\".nii.gz\")))\n",
    "  train_labels.append(file_reader(os.path.join(path,folders[0],name, name+\"_seg.nii.gz\")))\n",
    "\n",
    "\n",
    "test_data = []\n",
    "test_labels = []\n",
    "\n",
    "print(\"Val\")\n",
    "\n",
    "for i,name in enumerate(val_folders):\n",
    "  test_data.append(file_reader(os.path.join(path,folders[1],name, name+\".nii.gz\")))\n",
    "  test_labels.append(file_reader(os.path.join(path,folders[1],name, name+\"_seg.nii.gz\")))\n",
    "\n",
    "\n",
    "\n",
    "train_data = np.array(train_data)\n",
    "train_labels = np.array(train_labels)\n",
    "\n",
    "test_data = np.array(test_data)\n",
    "test_labels = np.array(test_labels)\n",
    "\n",
    "\n",
    "\n",
    "print(train_data.shape, train_labels.shape,  test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vTlk2D8dG7w8"
   },
   "outputs": [],
   "source": [
    "def file_header(filepath):\n",
    "    image_nifti = nib.load(filepath)\n",
    "    header = image_nifti.header  \n",
    "    return header\n",
    "\n",
    "path = \"/content/drive/My Drive/MISA project/misa data\"\n",
    "\n",
    "header_info=[]\n",
    "for i,name in enumerate(val_folders):\n",
    "  header_info.append(file_header(os.path.join(path,folders[1],name, name+\".nii.gz\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9CP6UQJUG_Qs"
   },
   "outputs": [],
   "source": [
    "# shuffle train : \n",
    "np.random.seed(0)\n",
    "x = list(range(train_data.shape[0]))\n",
    "randomize = np.arange(len(x))\n",
    "np.random.shuffle(randomize)\n",
    "train_data = train_data[randomize]\n",
    "train_labels = train_labels[randomize]\n",
    "\n",
    "print(train_data.shape, train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "td-RDvBz1lib"
   },
   "source": [
    "## Split train into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bmBqGsFHCIU"
   },
   "outputs": [],
   "source": [
    "# split train into validation and train \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_data, train_labels, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape, test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2jAUY1ib1oRZ"
   },
   "source": [
    "## Apply histogram equalization or other preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S5joT7w5HCR1"
   },
   "outputs": [],
   "source": [
    "# Apply ada histogram equalization on all data :\n",
    "\n",
    "from skimage.exposure import equalize_adapthist\n",
    "\n",
    "train = []\n",
    "val= []\n",
    "test = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "  train.append(equalize_adapthist(np.squeeze(X_train[i])))\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "  val.append(equalize_adapthist(np.squeeze(X_val[i])))\n",
    "\n",
    "for i in range(len(test_data)):\n",
    "  test.append(equalize_adapthist(np.squeeze(test_data[i])))\n",
    "\n",
    "train = np.array(train)\n",
    "val = np.array(val)\n",
    "test = np.array(test)\n",
    "\n",
    "print(train.shape, val.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "1Go_tMezHH43"
   },
   "outputs": [],
   "source": [
    "train_labels = y_train\n",
    "val_labels = y_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rop_eJqF1tZi"
   },
   "source": [
    "## Cut data into slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gqNu2q-cGzaG"
   },
   "outputs": [],
   "source": [
    "# Cut data into slices \n",
    "\n",
    "import pickle\n",
    "\n",
    "print('Train')\n",
    "tr_data = []\n",
    "tr_labels = []\n",
    "\n",
    "\n",
    "for i in range(len(train)):\n",
    "  vol = train[i]\n",
    "  vol_gt = np.squeeze(train_labels[i])\n",
    "  for j in range(256):\n",
    "    tr_data.append(vol[:,:,j])\n",
    "    tr_labels.append(vol_gt[:,:,j])\n",
    "\n",
    "print('Val')\n",
    "\n",
    "vl_data = []\n",
    "vl_labels = []\n",
    "\n",
    "for i in range(len(val)):\n",
    "  vol = val[i]\n",
    "  vol_gt = np.squeeze(val_labels[i])\n",
    "  for j in range(256):\n",
    "    vl_data.append(vol[:,:,j])\n",
    "    vl_labels.append(vol_gt[:,:,j])\n",
    "\n",
    "\n",
    "tst_data = []\n",
    "tst_labels = []\n",
    "\n",
    "for i in range(len(test)):\n",
    "  vol = test[i]\n",
    "  vol_gt = np.squeeze(test_labels[i])\n",
    "  for j in range(256):\n",
    "    tst_data.append(vol[:,:,j])\n",
    "    tst_labels.append(vol_gt[:,:,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i5rD3FB5HLLS"
   },
   "outputs": [],
   "source": [
    "train_data = np.expand_dims(np.array(tr_data), axis=3)\n",
    "val_data = np.expand_dims(np.array(vl_data), axis=3)\n",
    "test_data = np.expand_dims(np.array(tst_data), axis=3)\n",
    "\n",
    "train_labels = np.expand_dims(np.array(tr_labels), axis=3)\n",
    "val_labels = np.expand_dims(np.array(vl_labels), axis=3)\n",
    "test_labels = np.expand_dims(np.array(tst_labels), axis=3)\n",
    "\n",
    "print(train_data.shape, train_labels.shape, val_data.shape, val_labels.shape, test_data.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h2BY6C5s1w81"
   },
   "source": [
    "## Extract patches and useful patches "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jPLls48R1zyC"
   },
   "outputs": [],
   "source": [
    "IMAGE_SIZE = (256, 128, 256)\n",
    "\n",
    "N_INPUT_CHANNELS = 1\n",
    "PATCH_SIZE = (32, 32)\n",
    "PATCH_STRIDE = (16, 16)\n",
    "\n",
    "image_size = IMAGE_SIZE\n",
    "patch_size = PATCH_SIZE\n",
    "stride = PATCH_STRIDE\n",
    "\n",
    "\n",
    "def extract_patches(x, patch_size, patch_stride) :\n",
    "  return tf.image.extract_patches(\n",
    "    x,\n",
    "    sizes=[1, *patch_size, 1],\n",
    "    strides=[1, *patch_stride, 1],\n",
    "    rates=[1, 1, 1, 1],\n",
    "    padding='SAME', name=None)\n",
    "  \n",
    "\n",
    "def extract_useful_patches(\n",
    "    volumes, labels,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    patch_size=PATCH_SIZE,\n",
    "    stride=PATCH_STRIDE,\n",
    "    threshold=0.5,\n",
    "    num_classes=4) :\n",
    "\n",
    "  vol_patches = extract_patches(volumes, patch_size, stride).numpy()\n",
    "  seg_patches = extract_patches(labels, patch_size, stride).numpy()\n",
    "\n",
    "  vol_patches = vol_patches.reshape([-1, *patch_size, 1])\n",
    "  seg_patches = seg_patches.reshape([-1, *patch_size, ])\n",
    "\n",
    "  foreground_mask = seg_patches != 0\n",
    "\n",
    "  useful_patches = foreground_mask.sum(axis=(1, 2)) > threshold * np.prod(patch_size)\n",
    "\n",
    "  \n",
    "\n",
    "  vol_patches = vol_patches[useful_patches]\n",
    "  seg_patches = seg_patches[useful_patches]\n",
    "\n",
    "  seg_patches = tf.keras.utils.to_categorical(\n",
    "    seg_patches, num_classes=num_classes, dtype='float32')\n",
    "  \n",
    "  return (vol_patches, seg_patches)\n",
    "\n",
    "\n",
    "#extract from train and validation : \n",
    "\n",
    "(train_patches, train_patches_seg) = extract_useful_patches(train_data, train_labels)\n",
    "(val_patches, val_patches_seg) = extract_useful_patches(val_data, val_labels)\n",
    "\n",
    "print(train_patches.shape, train_patches_seg.shape, val_patches.shape, val_patches_seg.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "to6yChqM1-5f"
   },
   "source": [
    "## Oversampling for CSF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vz10TtSb2JAl"
   },
   "outputs": [],
   "source": [
    "number, x, y, _ = train_patches.shape\n",
    "\n",
    "csf = []\n",
    "idx = []\n",
    "for i in range(number):\n",
    "  if np.sum(train_patches_seg[i,:,:,1]) == 0:\n",
    "    continue\n",
    "  elif np.sum(train_patches_seg[i,:,:,1]) > 200:\n",
    "    idx.append(i)\n",
    "    csf.append(train_patches_seg[i,:,:,1])\n",
    "csf = np.array(csf)\n",
    "csf.shape\n",
    "\n",
    "\n",
    "csf_filled = train_patches[idx]\n",
    "csf_filled_mask = train_patches_seg[idx]\n",
    "\n",
    "upsampleRate = 50\n",
    "\n",
    "for i in range(upsampleRate):\n",
    "  train_patches = np.append(train_patches,csf_filled, axis = 0)\n",
    "  train_patches_seg= np.append(train_patches_seg, csf_filled_mask, axis = 0)\n",
    "\n",
    "train_patches.shape, train_patches_seg.shape\n",
    "\n",
    "x = list(range(train_patches.shape[0]))\n",
    "randomize = np.arange(len(x))\n",
    "np.random.shuffle(randomize)\n",
    "train_patches = train_patches[randomize]\n",
    "train_patches_seg = train_patches_seg[randomize]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uPjDAtqi2Jbz"
   },
   "source": [
    "## Calculate percentage of each class in the train patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DihaPPTr2GU9"
   },
   "outputs": [],
   "source": [
    "number, x, y, _ = train_patches_seg.shape\n",
    "\n",
    "num = number*x*y\n",
    "names = ['BG', 'CSF', 'GM', 'WM']\n",
    "\n",
    "for i in range(4):\n",
    "  print(f\"{names[i]}: {np.round(np.sum(train_patches_seg[:,:,:,i])/num, 3)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nz_tOTK_2OXK"
   },
   "source": [
    "## Define 2D UNET architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "zuS5MD8NGzdo"
   },
   "outputs": [],
   "source": [
    "# Define Unet : \n",
    "\n",
    "N_EPOCHS = 20\n",
    "BATCH_SIZE = 64\n",
    "PATIENCE = 10\n",
    "MODEL_FNAME_PATTERN = 'model.h5'\n",
    "OPTIMISER = 'Adam'\n",
    "LOSS = 'categorical_crossentropy'\n",
    "\n",
    "# network parameters\n",
    "N_CLASSES = 4\n",
    "N_INPUT_CHANNELS = 1\n",
    "PATCH_SIZE = (32, 32)\n",
    "\n",
    "\n",
    "\n",
    "def get_unet(img_size=PATCH_SIZE, n_classes=N_CLASSES, n_input_channels=N_INPUT_CHANNELS, scale=2, drp_rate=0.2):\n",
    "    inputs = keras.Input(shape=img_size + (n_input_channels, ))\n",
    "\n",
    "    # Encoding path\n",
    "    conv1 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(inputs)\n",
    "    drop1 = layers.Dropout(rate=drp_rate)(conv1, training=True)\n",
    "    max1 = layers.MaxPooling2D((2, 2))(drop1)\n",
    "\n",
    "    conv2 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(max1)\n",
    "    drop2 = layers.Dropout(rate=drp_rate)(conv2, training=True)\n",
    "    max2 = layers.MaxPooling2D((2, 2))(drop2)\n",
    "\n",
    "    conv3 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(max2)\n",
    "    drop3 = layers.Dropout(rate=drp_rate)(conv3, training=True)\n",
    "    max3 = layers.MaxPooling2D((2, 2))(drop3)\n",
    "\n",
    "    lat = layers.Conv2D(256*scale, (3, 3), padding=\"same\", activation='relu')(max3)\n",
    "    drop4 = layers.Dropout(rate=drp_rate)(lat, training=True)\n",
    "\n",
    "    # Decoding path\n",
    "    \n",
    "    up1 = layers.UpSampling2D((2, 2))(drop4)\n",
    "    concat1 = layers.concatenate([conv3, up1], axis=-1)\n",
    "    conv4 = layers.Conv2D(128*scale, (3, 3), padding=\"same\", activation='relu')(concat1)\n",
    "    drop5 = layers.Dropout(rate=drp_rate)(conv4, training=True)\n",
    "\n",
    "    up2 = layers.UpSampling2D((2, 2))(drop5)\n",
    "    concat2 = layers.concatenate([conv2, up2], axis=-1)\n",
    "    conv5 = layers.Conv2D(64*scale, (3, 3), padding=\"same\", activation='relu')(concat2)\n",
    "    drop6 = layers.Dropout(rate=drp_rate)(conv5, training=True)\n",
    "    \n",
    "    up3 = layers.UpSampling2D((2, 2))(drop6)\n",
    "    concat3 = layers.concatenate([conv1, up3], axis=-1)\n",
    "    conv6 = layers.Conv2D(32*scale, (3, 3), padding=\"same\", activation='relu')(concat3)\n",
    "    drop7 = layers.Dropout(rate=drp_rate)(conv6, training=True)\n",
    "\n",
    "    outputs = layers.Conv2D(n_classes, (1, 1), activation=\"softmax\")(drop7)\n",
    "\n",
    "    model = keras.Model(inputs, outputs)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XXfOFQ5x2V92"
   },
   "source": [
    "## Compile and train model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t2LCw82I2Ydq"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "weights_dir = \"/content/drive/My Drive/misa_unet_optim.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=weights_dir, save_weights_only=True, monitor='val_loss', verbose=1,\n",
    "    save_best_only=True, mode='auto', period=1)\n",
    "\n",
    "unet = get_unet()\n",
    "unet.compile(optimizer=OPTIMISER, loss=LOSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xKahTIOZ2aTB"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 15\n",
    "unet.fit(\n",
    "    x=train_patches, \n",
    "    y=train_patches_seg,\n",
    "    validation_data=(val_patches, val_patches_seg),\n",
    "    batch_size=64,\n",
    "    epochs=EPOCHS, \n",
    "    callbacks = checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8t6cbSg2a5S"
   },
   "source": [
    "## Load best weights and redifine input size for the validation set prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YIILN7KXHWPG"
   },
   "outputs": [],
   "source": [
    "#load model with weights and compile \n",
    "unet_bis = get_unet(\n",
    "    img_size=(256, 128),\n",
    "    n_classes=N_CLASSES,\n",
    "    n_input_channels=1)\n",
    "\n",
    "unet_bis.compile(optimizer=OPTIMISER, loss=LOSS)\n",
    "unet_bis.load_weights(\"/content/drive/My Drive/misa_unet.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9Bj4cw6a1ZI5"
   },
   "source": [
    "## Calculate DICE on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oY8-9luhHqT9"
   },
   "outputs": [],
   "source": [
    "def get_dice(seg,gt):\n",
    "    dice = [] \n",
    "    for i in range(4):\n",
    "        print(i)\n",
    "        d = np.sum(seg[gt==i]==i)*2.0 / (np.sum(seg[seg==i]==i) + np.sum(gt[gt==i]==i))\n",
    "        print('Dice similarity score is {}'.format(d))\n",
    "        dice.append(d)\n",
    "    return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8tuoonVWHsx2"
   },
   "outputs": [],
   "source": [
    "#predict on validation \n",
    "\n",
    "prediction = unet_bis.predict(test_data)\n",
    "\n",
    "prediction = np.argmax(prediction, axis=3)\n",
    "validation_labels = np.squeeze(test_labels)\n",
    "dice = get_dice(test_labels, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGQDxJzs1cXR"
   },
   "source": [
    "## Calculate relative volumetric difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pt8opBYHvO7"
   },
   "outputs": [],
   "source": [
    "## VD\n",
    "\n",
    "# 100 * (segm.sum() - gt.sum()) / float(gt.sum())\n",
    "\n",
    "def get_vd(seg,gt):\n",
    "  vd =[]\n",
    "  for i in range(4):\n",
    "    print(i)\n",
    "    v = 100*((np.sum(seg[seg==i])-np.sum(gt[gt==i]))/np.sum(gt[gt==i]))\n",
    "    print('vd {} '.format(v))\n",
    "    vd.append(v)\n",
    "  return vd\n",
    "\n",
    "vd = get_vd(prediction,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S1Yx_I3Y1S3H"
   },
   "source": [
    "## transform to volumes again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "7uZufg-QJ-DS"
   },
   "outputs": [],
   "source": [
    "def get_volume(slices):\n",
    "  shape = slices.shape[0]\n",
    "  iter = int(shape/256)\n",
    "  volumes = np.zeros((iter,256,128,256))\n",
    "  for i in range(iter):\n",
    "    vol = np.zeros((256,128,256))\n",
    "    for j in range(256):\n",
    "      vol[:,:,j]= slices[j+i*256]\n",
    "    volumes[i]= vol\n",
    "  return volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rogk99YAJ-4t"
   },
   "outputs": [],
   "source": [
    "test_predictions = get_volume(prediction)\n",
    "\n",
    "print(test_predictions.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lx7Pwt0G1WFH"
   },
   "source": [
    "## Save as NIFTII FILES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "U2YMLqXWIeSP"
   },
   "outputs": [],
   "source": [
    "# save them onto nifti files: \n",
    "\n",
    "for i in range(5):\n",
    "\n",
    "    ni_img_i = nib.Nifti1Image(test_predictions[i], affine=np.eye(4), header = header_info[i])\n",
    "    header = header_info[i]\n",
    "    ni_img_i.header['pixdim'][1:4] = header['pixdim'][1:4]\n",
    "    nib.save(ni_img_i, '/content/drive/My Drive/'+f'predicted_test_volume_labels{i+1}.nii.gz')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "misa final final final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
